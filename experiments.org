Content-Type: text/enriched
Text-Width: 70

<x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+TITLE:</x-color></x-bg-color> <x-color><param>black</param>Experimental Evaluation of $r$-Gather Algorithms for Point-Sets and Trajectories
</x-color><x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+DATE:</x-color></x-bg-color> <x-color><param>#484848</param>.
</x-color><x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+AUTHOR:</x-color></x-bg-color><x-color><param>#484848</param>
</x-color><x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+LATEX_HEADER: \usepackage[margin=0.5in]{geometry}</x-color></x-bg-color>
<x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+OPTIONS: toc:nil</x-color></x-bg-color>
<x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+LATEX_HEADER_EXTRA:  \usepackage{mdframed}</x-color></x-bg-color>
<x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}</x-color></x-bg-color>
<x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}</x-color></x-bg-color>
<x-bg-color><param>#E2E1D5</param><x-color><param>#555555</param>#+begin_comment
</x-color></x-bg-color>- Technical details <bold>*Anaconda 2.5.0*</bold> Python 2.7,  Numpy, Scipy, Matplotlib, NetworkX, ffmpeg Ubuntu 14.04 system. (Python 2.7.12  Anaconda 2.5.0 (64-bit)) 
  The code is available for download and review  from .git to be able to download and run. Mention the laptop and the processor too.  
  Make sure you mention anaconda, else the code will crash. Send Vinay this code and <bold>*Intel(R) Core(TM) i3 CPU M 330 @ 2.13GHz*</bold>, this 
  processor is ancient by modern standards. Make sure it works on his computer. This file will be important since you can stuff a ton of 
  details and assumptions made about the algorithms which will not be interesting at all in the paper. <bold>*Tangle and run*</bold>, that should be the 
  work-flow for the referee to generate all the plots there in. The appendix will contains the link to the noweb-references of function 
  definitions and then run the actual experiments themselves for all the various possible parameters. You can also use <bold>*Github's _wiki_*</bold> 
  facility to give other installation instructions. The README.md file can also be useful. The full packaging will be very important. 
  I will make this an industry standard in of how to publish reproducible research. Mention about the existence of this literate file! 
  This will be very important! Mention the emacs version so that the people can tangle the damn thing across all platforms.  <bold>*GNU Emacs 24.5.1*</bold> 
  Make sure that the link to the github page will open a browser okay? The text for github should be linkable either as a reference or be 
  inserted in place.


<bold>*Meta note:*</bold> It is important that you get the experiment framework ready. That framework can (in fact should) withstand changes made to the 
main algorithm file. The experiments should be written as a suite of tools.(??) Also, <bold>*don't use*</bold> the input files you generated from the infocom 
draft. just use the super function you wrote in the utitlities. An engine to supply the data, from relevant input files generated separately.


The goal of this literate-set of documents is for the referee to be able to tangle and run, the code. He should be able to set the parameters.

by himself is he so desires and see the results for himself. Submitting the code is part of the advertisement of the scholarship.


- To run the code, download, <bold>*experiments.org*</bold> (this file). <bold>*rGather.py*</bold> (containing the libraries) are the main files in them.  

- Along with this are the <bold>*videos*</bold> which can be used for more specific illustrations. In particular, feel free to make references to 
  the github package. Make sure that any path-links are <bold>*relative*</bold>, so that the experiments can be run easily. Test this out on 
  Vinay's computer or someone else's/. 

- Present also are the data-files from which the plots were generated. The plots and data-files in turn are generated by the code in this file. 
  This will allow the referee to download the code, and test-it 

<bold>*I will present the material in the following manner.*</bold> 

0. Mention the setup of the experiments. Some of these instructions can also go into the appendix. 
   - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> Language and environment
   - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> Additional libraries that will be needed to run on a particular platform. <x-color><param>#006DAF</param>https://docs.continuum.io/anaconda/pkg-docs</x-color>
         See the tick-marks on the right. Thankfully, YAML comes prebuilt. 
   - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> Give a link to the online github repository containing 
           - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> rGather.py
           - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> Videos, such as the one you generated. I think there is an online ,mp4 player for github. 
                 I am sure this can be done really easily on github.
           - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> The .org file and the generated .pdf file. with instructions for tangling.
           - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> A glue script that runs all the experiments in tandem, (possibly in different threads)
                 Note that in order that the computation not block, <bold>*make sure, you don't use plt.show()*</bold>
                 and save to a sub-folder directly. 

1. Examples of clustering. These should probably come near the beginning of the paper. Keeping them near the end sort is backward thinking. 
   Mention this to everyone. Roughly speaking the distribution of concepts is this. Think of this as a 2x2 table.
   My estimate is that there will be approximately two plots per cell. 

2. The quality of the clustering can be evaluated by several criteria 
   - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> <bold>*Max diameter*</bold> of resulting clusters: 2-apx vs 4-apx, for <underline>_point-sets and trajectories_</underline>
   - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> <bold>*Max distance cluster center*</bold>. 2-apx vs 4-apx for <underline>_point-sets and trajectories_</underline>
   - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> <bold>*90-percentile Max diameter*</bold> of resulting clusters: for <underline>_point-sets and trajectories_</underline>
   - <x-bg-color><param>#777777</param><x-color><param>white</param>[ ]</x-color></x-bg-color> <bold>*90-percentile distance to cluster center*</bold> 2-apx vs 4-apx, for <underline>_point-sets and trajectories_</underline>

   This gives you <bold>*16*</bold> core-plots in all. 

   Along with this, Joe wants you to plot for the scenario of $R(t)$. for the case that you visualized. 
   As an add-on you can visualize the cluster in xy-t space if you want.

<bold>*Appendix*</bold>

<underline>_On saving plots to disk_</underline>
  By looking at the file-extension, matplotlib can automatically generate the appropriate back-end to write to disk. 
  You should use <bold>*eps*</bold>, possibly svg as a back-up although there are convertors from one to the other, so it is not a big issue. 

  e.g. The command for doing this is fig.savefig(filename) Note that you dont have a .save style method for ax objects. 
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rc
#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})
rc('font',**{'family':'serif','serif':['Helvetica']}) # Or you can fall-back on the classic 'Times'
rc('text', usetex=True)


fig, ax = plt.subplots(1,2)
x = np.linspace(-np.pi, np.pi, 100)
y = np.sin(x)

ax[0].plot(x,y)
ax[1].plot(x,y)

ax[0].set_title(r"Decentralized static r-gather", fontsize=28)
ax[0].set_xlabel('xlabel')
ax[0].set_xlabel(r"\TeX\ is Number "
          r"$\displaystyle\sum_{n=1}^\infty\frac{-e^{i\pi}}{2^n}$!",
          fontsize=16)

ax[1].set_title(r"Decentralized static r-gather", fontsize=14)
ax[1].set_xlabel('xlabel')
ax[1].set_xlabel(r"\TeX\ is Number "
          r"$\displaystyle\sum_{n=1}^\infty\frac{-e^{i\pi}}{2^n}$!",
          fontsize=16)

<bold>*fig.suptitle('My Large Plot Title', fontsize=28)*</bold>
<bold>*fig.savefig('scrap.svg')*</bold>
<bold>*print "File saved to disk # See ma! No hands!*</bold> # Note that there is no plt.show()! 
This function blocks in non-interactive mode, but <bold>*not*</bold> in interactive mode. 
See th edocs.This is very useful to know.

<underline>_On YAML_</underline>
   I will be using YAML for storing data and communicating it between processes. 
   To write something to a yaml file, in standard ascii format, you create a <bold>*dictionary*</bold>, and then use yaml to dump 
   a string in the yaml format. This string is then written to disk, the normal way you write strings to disk.
   e.g.
   D = {'hello':1, 'world':2}  # Make a dictionary to stuff data.
   <bold>*yamlstring = yaml.dump(D)*</bold> # this is the key-step.
   with open( outputpath, 'w' ) as outfile: # <bold>*Write to a file as you would a normal string. So sweet, innit?*</bold>
              outfile.write( yamlstring )

   This is the write way to communicate between programs, via yaml strings. Sophisticated yaml parsers 
   will help you read the data. It is this yaml string that can be sent "over the wire" as the saying goes.
   In particular, this yaml string can also be sent over the wire to visualize using the VTK libraries.<x-bg-color><param>#EAEAFF</param><x-color><param>#008ED1</param>
</x-color></x-bg-color><x-bg-color><param>#E2E1D5</param><x-color><param>#555555</param>#+end_comment

</x-color></x-bg-color>



<x-bg-color><param>#F0F0F0</param><x-color><param>#3C3C3C</param>* Experimental Results</x-color></x-bg-color>

  To investigate the quality of the clusters returned by the algorithms just described, we implemented and tested them on a real-world

  data set of the GPS trajectories of cars driving around Shenzhen in China. The next few sub-sections give a comparitive evaluations and

  statistics found by running the algorithms on that data-set.


<x-bg-color><param>#E5F4FB</param><x-color><param>#123555</param>** Experimental Setup</x-color></x-bg-color>

   All algorithms were implemented using the Python 2.7.12 :: Anaconda 2.5.0 distribution on an HP-laptop with a core-i3 processor and the

   Ubuntu 14.04 operating system. Our code can be downloaded for review and testing from the github repository 

   

